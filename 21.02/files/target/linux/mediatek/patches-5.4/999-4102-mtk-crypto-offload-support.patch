--- a/drivers/net/ethernet/mediatek/mtk_eth_soc.c
+++ b/drivers/net/ethernet/mediatek/mtk_eth_soc.c
@@ -1990,6 +1990,7 @@ static void mtk_tx_set_dma_desc_v3(struc
 	u32 data = 0;
 	u8 tops_entry  = 0;
 	u8 tport = 0;
+	u8 cdrt = 0;
 
 	WRITE_ONCE(desc->txd1, info->addr);
 
@@ -2014,11 +2015,25 @@ static void mtk_tx_set_dma_desc_v3(struc
 	trace_printk("[%s] skb_shinfo(skb)->nr_frags=%x HNAT_SKB_CB2(skb)->magic=%x txd4=%x<-----\n",
 		     __func__, skb_shinfo(skb)->nr_frags, HNAT_SKB_CB2(skb)->magic, data);
 #endif
-	if (mtk_get_tnl_netsys_params && skb) {
+	if (mtk_get_tnl_netsys_params && skb && !(skb->inner_protocol == IPPROTO_ESP)) {
 		u32 params = mtk_get_tnl_netsys_params(skb);
 
 		tops_entry = params & 0x000000FF;
 		tport = (params & 0x0000FF00) >> 8;
+		cdrt = (params & 0x00FF0000) >> 16;
+	}
+	/* forward to eip197 if this packet is going to encrypt */
+#if defined(CONFIG_NET_MEDIATEK_HNAT) || defined(CONFIG_NET_MEDIATEK_HNAT_MODULE)
+	else if (unlikely(skb->inner_protocol == IPPROTO_ESP && skb_hnat_cdrt(skb) && is_magic_tag_valid(skb))) {
+		/* carry cdrt index for encryption */
+		cdrt = skb_hnat_cdrt(skb);
+		skb_hnat_magic_tag(skb) = 0;
+#else
+	else if (unlikely(skb->inner_protocol == IPPROTO_ESP && skb_tnl_cdrt(skb) && is_tnl_tag_valid(skb))) {
+		cdrt = skb_tnl_cdrt(skb);
+		skb_tnl_magic_tag(skb) = 0;
+#endif
+		tport = EIP197_QDMA_TPORT;
 	}
 
 	if (tport) {
@@ -2055,6 +2070,11 @@ static void mtk_tx_set_dma_desc_v3(struc
 		data |= (tops_entry & TX_DMA_TOPS_ENTRY_MASK) << TX_DMA_TOPS_ENTRY_SHIFT;
 	}
 
+	if (cdrt) {
+		data &= ~(TX_DMA_CDRT_MASK << TX_DMA_CDRT_SHIFT);
+		data |= (cdrt & TX_DMA_CDRT_MASK) << TX_DMA_CDRT_SHIFT;
+	}
+
 	WRITE_ONCE(desc->txd8, data);
 }
 
@@ -2568,6 +2588,7 @@ static int mtk_poll_rx(struct napi_struc
 
 		skb_hnat_alg(skb) = 0;
 		skb_hnat_filled(skb) = 0;
+		skb_hnat_set_cdrt(skb, 0);
 		skb_hnat_magic_tag(skb) = HNAT_MAGIC_TAG;
 		skb_hnat_set_tops(skb, 0);
 		skb_hnat_set_is_decap(skb, 0);
--- a/drivers/net/ethernet/mediatek/mtk_hnat/hnat_nf_hook.c
+++ b/drivers/net/ethernet/mediatek/mtk_hnat/hnat_nf_hook.c
@@ -1091,6 +1091,9 @@ static unsigned int hnat_ipv4_get_nextho
 		return 0;
 	}
 
+	if (!skb_hnat_cdrt(skb) && dst && dst_xfrm(dst))
+		return 0;
+
 	rcu_read_lock_bh();
 	nexthop = (__force u32)rt_nexthop(rt, ip_hdr(skb)->daddr);
 	neigh = __ipv4_neigh_lookup_noref(dev, nexthop);
@@ -1298,6 +1301,9 @@ static inline void hnat_fill_offload_eng
 		 */
 		entry->ipv4_hnapt.tport_id = NR_TDMA_QDMA_TPORT;
 		entry->ipv4_hnapt.tops_entry = skb_hnat_tops(skb);
+	} else if (skb_hnat_cdrt(skb)) {
+		entry->ipv4_hnapt.tport_id = NR_EIP197_QDMA_TPORT;
+		entry->ipv4_hnapt.cdrt_id = skb_hnat_cdrt(skb);
 	} else {
 		return;
 	}
@@ -1307,6 +1313,158 @@ static inline void hnat_fill_offload_eng
 #endif /* defined(CONFIG_MEDIATEK_NETSYS_V3) */
 }
 
+int hnat_bind_crypto_entry(struct sk_buff *skb, const struct net_device *dev, int fill_inner_info) {
+	struct foe_entry *foe;
+	struct foe_entry entry = { 0 };
+	struct ethhdr *eth = eth_hdr(skb);
+	struct iphdr *iph;
+	struct tcpudphdr _ports;
+	const struct tcpudphdr *pptr;
+	u32 gmac = NR_DISCARD;
+	int udp = 0;
+	struct mtk_mac *mac = netdev_priv(dev);
+	struct flow_offload_hw_path hw_path = { .dev = (struct net_device *) dev,
+						.virt_dev = (struct net_device *) dev };
+
+	if (!skb_hnat_is_hashed(skb) || skb_hnat_ppe(skb) >= CFG_PPE_NUM)
+		return 0;
+
+	foe = &hnat_priv->foe_table_cpu[skb_hnat_ppe(skb)][skb_hnat_entry(skb)];
+
+	if (entry_hnat_is_bound(foe))
+		return 0;
+
+	if (eth->h_proto != htons(ETH_P_IP))
+		return 0;
+
+	if (skb_hnat_tops(skb) && mtk_tnl_encap_offload)
+		mtk_tnl_encap_offload(skb);
+
+	hnat_get_filled_unbind_entry(skb, &entry);
+
+	if (dev->netdev_ops->ndo_flow_offload_check)
+		dev->netdev_ops->ndo_flow_offload_check(&hw_path);
+
+	/* For packets pass through VTI (route-based IPSec),
+	 * We need to fill the inner packet info into hnat entry.
+	 * Since the skb->mac_header is not pointed to correct position
+	 * in skb_to_hnat_info().
+	 */
+	if (fill_inner_info) {
+		iph = ip_hdr(skb);
+		switch (iph->protocol) {
+		case IPPROTO_UDP:
+			udp = 1;
+			/* fallthrough */
+		case IPPROTO_TCP:
+			entry.ipv4_hnapt.etype = htons(ETH_P_IP);
+			if (IS_IPV4_GRP(&entry)) {
+				entry.ipv4_hnapt.iblk2.dscp = iph->tos;
+				if (hnat_priv->data->per_flow_accounting)
+					entry.ipv4_hnapt.iblk2.mibf = 1;
+
+				entry.ipv4_hnapt.vlan1 = hw_path.vlan_id;
+
+				if (skb_vlan_tagged(skb)) {
+					entry.bfib1.vlan_layer += 1;
+
+					if (entry.ipv4_hnapt.vlan1)
+						entry.ipv4_hnapt.vlan2 =
+							skb->vlan_tci;
+					else
+						entry.ipv4_hnapt.vlan1 =
+							skb->vlan_tci;
+				}
+
+				entry.ipv4_hnapt.sip = foe->ipv4_hnapt.sip;
+				entry.ipv4_hnapt.dip = foe->ipv4_hnapt.dip;
+				entry.ipv4_hnapt.sport = foe->ipv4_hnapt.sport;
+				entry.ipv4_hnapt.dport = foe->ipv4_hnapt.dport;
+
+				entry.ipv4_hnapt.new_sip = ntohl(iph->saddr);
+				entry.ipv4_hnapt.new_dip = ntohl(iph->daddr);
+
+				if (IS_IPV4_HNAPT(&entry)) {
+					pptr = skb_header_pointer(skb, iph->ihl * 4 + ETH_HLEN,
+								sizeof(_ports),
+								&_ports);
+					if (unlikely(!pptr))
+						return -1;
+
+					entry.ipv4_hnapt.new_sport = ntohs(pptr->src);
+					entry.ipv4_hnapt.new_dport = ntohs(pptr->dst);
+				}
+			} else
+				return 0;
+
+			entry.ipv4_hnapt.bfib1.udp = udp;
+
+#if defined(CONFIG_MEDIATEK_NETSYS_V3)
+				entry.ipv4_hnapt.eg_keep_ecn = 1;
+				entry.ipv4_hnapt.eg_keep_dscp = 1;
+#endif
+			break;
+
+		default:
+			return -1;
+		}
+	}
+
+	entry = ppe_fill_info_blk(eth, entry, &hw_path);
+
+	if (IS_LAN(dev)) {
+		if (IS_BOND_MODE)
+			gmac = ((skb_hnat_entry(skb) >> 1) % hnat_priv->gmac_num) ?
+				 NR_GMAC2_PORT : NR_GMAC1_PORT;
+		else
+			gmac = NR_GMAC1_PORT;
+	} else if (IS_LAN2(dev)) {
+		gmac = (mac->id == MTK_GMAC2_ID) ? NR_GMAC2_PORT : NR_GMAC3_PORT;
+	} else if (IS_WAN(dev)) {
+		if (IS_GMAC1_MODE)
+			gmac = NR_GMAC1_PORT;
+		else
+			gmac = (mac->id == MTK_GMAC2_ID) ? NR_GMAC2_PORT : NR_GMAC3_PORT;
+	} else {
+		pr_notice("Unknown case of dp, iif=%x --> %s\n", skb_hnat_iface(skb), dev->name);
+		return -1;
+	}
+
+	entry.ipv4_hnapt.iblk2.mibf = 1;
+	entry.ipv4_hnapt.iblk2.dp = gmac;
+	entry.ipv4_hnapt.iblk2.port_mg =
+		(hnat_priv->data->version == MTK_HNAT_V1_1) ? 0x3f : 0;
+	entry.bfib1.ttl = 1;
+	entry.bfib1.state = BIND;
+
+	hnat_fill_offload_engine_entry(skb, &entry, dev);
+
+	if (!skb_hnat_tops(skb)) {
+		entry.ipv4_hnapt.dmac_hi = swab32(*((u32 *)eth->h_dest));
+		entry.ipv4_hnapt.dmac_lo = swab16(*((u16 *)&eth->h_dest[4]));
+		entry.ipv4_hnapt.smac_hi = swab32(*((u32 *)eth->h_source));
+		entry.ipv4_hnapt.smac_lo = swab16(*((u16 *)&eth->h_source[4]));
+	}
+
+	wmb();
+
+	if (entry_hnat_is_bound(foe))
+		return 0;
+
+	spin_lock(&hnat_priv->entry_lock);
+	memcpy(foe, &entry, sizeof(entry));
+	spin_unlock(&hnat_priv->entry_lock);
+
+	if (hnat_priv->data->per_flow_accounting &&
+	    skb_hnat_entry(skb) < hnat_priv->foe_etry_num &&
+	    skb_hnat_ppe(skb) < CFG_PPE_NUM)
+		memset(&hnat_priv->acct[skb_hnat_ppe(skb)][skb_hnat_entry(skb)],
+		       0, sizeof(struct mib_entry));
+
+	return 0;
+}
+EXPORT_SYMBOL(hnat_bind_crypto_entry);
+
 static unsigned int skb_to_hnat_info(struct sk_buff *skb,
 				     const struct net_device *dev,
 				     struct foe_entry *foe,
@@ -2438,6 +2596,7 @@ int mtk_sw_nat_hook_rx(struct sk_buff *s
 	skb_hnat_alg(skb) = 0;
 	skb_hnat_filled(skb) = 0;
 	skb_hnat_set_tops(skb, 0);
+	skb_hnat_set_cdrt(skb, 0);
 	skb_hnat_magic_tag(skb) = HNAT_MAGIC_TAG;
 
 	if (skb_hnat_iface(skb) == FOE_MAGIC_WED0)
@@ -2524,7 +2683,8 @@ static unsigned int mtk_hnat_accel_type(
 	 * is from local_out which is also filtered in sanity check.
 	 */
 	dst = skb_dst(skb);
-	if (dst && dst_xfrm(dst))
+	if (dst && dst_xfrm(dst)
+	    && (!mtk_crypto_offloadable || !mtk_crypto_offloadable(skb)))
 		return 0;
 
 	ct = nf_ct_get(skb, &ctinfo);
@@ -2906,6 +3066,14 @@ static unsigned int mtk_hnat_nf_post_rou
 		}
 	}
 
+	/* we are not support protocols other than IPv4 TCP for crypto offload yet */
+	if (skb_hnat_is_decrypt(skb)
+	    && (ntohs(skb->protocol) != ETH_P_IP
+		|| ip_hdr(skb)->protocol != IPPROTO_TCP)) {
+		skb_hnat_alg(skb) = 1;
+		return 0;
+	}
+
 	if (!IS_LAN_GRP(out) && !IS_WAN(out) && !IS_EXT(out))
 		is_virt_dev = true;
 
@@ -3213,7 +3381,10 @@ mtk_hnat_ipv4_nf_local_out(void *priv, s
 	if (iph->protocol == IPPROTO_IPV6) {
 		entry->udib1.pkt_type = IPV6_6RD;
 		hnat_set_head_frags(state, skb, 0, hnat_set_alg);
-	} else if (!skb_hnat_tops(skb)) {
+	} else if (is_magic_tag_valid(skb)
+		   && (skb_hnat_cdrt(skb) || skb_hnat_tops(skb))) {
+		hnat_set_head_frags(state, skb, 0, hnat_set_alg);
+	} else {
 		hnat_set_head_frags(state, skb, 1, hnat_set_alg);
 	}
 
--- a/drivers/net/ethernet/mediatek/mtk_hnat/nf_hnat_mtk.h
+++ b/drivers/net/ethernet/mediatek/mtk_hnat/nf_hnat_mtk.h
@@ -46,7 +46,8 @@ struct hnat_desc {
 	u32 amsdu : 1;
 	u32 tops : 6;
 	u32 is_decap : 1;
-	u32 resv3 : 12;
+	u32 cdrt : 8;
+	u32 resv3 : 4;
 	u32 magic_tag_protect : 16;
 } __packed;
 #elif defined(CONFIG_MEDIATEK_NETSYS_RX_V2)
@@ -100,12 +101,16 @@ struct hnat_desc {
 #define skb_hnat_is_encap(skb) (!skb_hnat_is_decap(skb))
 #define skb_hnat_set_tops(skb, tops) ((skb_hnat_tops(skb)) = (tops))
 #define skb_hnat_set_is_decap(skb, is_decap) ((skb_hnat_is_decap(skb)) = (is_decap))
+#define skb_hnat_cdrt(skb) (((struct hnat_desc *)((skb)->head))->cdrt)
+#define skb_hnat_set_cdrt(skb, cdrt) ((skb_hnat_cdrt(skb)) = (cdrt))
 #else /* !defined(CONFIG_MEDIATEK_NETSYS_V3) */
 #define skb_hnat_tops(skb) (0)
 #define skb_hnat_is_decap(skb) (0)
 #define skb_hnat_is_encap(skb) (0)
 #define skb_hnat_set_tops(skb, tops)
 #define skb_hnat_set_is_decap(skb, is_decap)
+#define skb_hnat_cdrt(skb) (0)
+#define skb_hnat_set_cdrt(skb, cdrt)
 #endif /* defined(CONFIG_MEDIATEK_NETSYS_V3) */
 #define skb_hnat_magic(skb) (((struct hnat_desc *)(skb->head))->magic)
 #define skb_hnat_reason(skb) (((struct hnat_desc *)(skb->head))->crsn)
--- a/drivers/net/ethernet/mediatek/mtk_hnat/hnat.c
+++ b/drivers/net/ethernet/mediatek/mtk_hnat/hnat.c
@@ -57,6 +57,8 @@ int (*mtk_tnl_decap_offload)(struct sk_b
 EXPORT_SYMBOL(mtk_tnl_decap_offload);
 bool (*mtk_tnl_decap_offloadable)(struct sk_buff *skb) = NULL;
 EXPORT_SYMBOL(mtk_tnl_decap_offloadable);
+bool (*mtk_crypto_offloadable)(struct sk_buff *skb) = NULL;
+EXPORT_SYMBOL(mtk_crypto_offloadable);
 
 int (*hnat_set_wdma_pse_port_state)(u32 wdma_idx, bool up) = NULL;
 EXPORT_SYMBOL(hnat_set_wdma_pse_port_state);
--- a/drivers/net/ethernet/mediatek/mtk_hnat/hnat.h
+++ b/drivers/net/ethernet/mediatek/mtk_hnat/hnat.h
@@ -1153,6 +1153,8 @@ enum FoeIpAct {
 #define NR_WDMA2_PORT 13
 #define NR_GMAC3_PORT 15
 #define NR_QDMA_TPORT 1
+#define NR_EIP197_TPORT 2
+#define NR_EIP197_QDMA_TPORT 3
 #define NR_TDMA_TPORT 4
 #define NR_TDMA_QDMA_TPORT 5
 #define LAN_DEV_NAME hnat_priv->lan
@@ -1334,6 +1336,9 @@ extern int qos_toggle;
 extern int (*mtk_tnl_encap_offload)(struct sk_buff *skb);
 extern int (*mtk_tnl_decap_offload)(struct sk_buff *skb);
 extern bool (*mtk_tnl_decap_offloadable)(struct sk_buff *skb);
+extern bool (*mtk_crypto_offloadable)(struct sk_buff *skb);
+extern int hnat_bind_crypto_entry(struct sk_buff *skb, const struct net_device *dev,
+					int fill_inner_info);
 
 int ext_if_add(struct extdev_entry *ext_entry);
 int ext_if_del(struct extdev_entry *ext_entry);
--- a/drivers/net/ethernet/mediatek/mtk_eth_soc.h
+++ b/drivers/net/ethernet/mediatek/mtk_eth_soc.h
@@ -576,6 +576,8 @@
 #define MTK_QDMA_GMAC3_QID	6
 
 /* QDMA V2 descriptor txd8 */
+#define TX_DMA_CDRT_SHIFT          0
+#define TX_DMA_CDRT_MASK           0xff
 #define TX_DMA_TOPS_ENTRY_SHIFT    8
 #define TX_DMA_TOPS_ENTRY_MASK     0x3f
 
@@ -588,6 +590,7 @@
 #define TX_DMA_SPTAG_V3            BIT(27)
 
 /* QDMA V2 descriptor txd4 */
+#define EIP197_QDMA_TPORT          3
 #define TX_DMA_TPORT_SHIFT         0
 #define TX_DMA_TPORT_MASK          0xf
 #define TX_DMA_FPORT_SHIFT_V2      8
@@ -1075,6 +1078,43 @@
 #define MT7628_SDM_MAC_ADRL	(MT7628_SDM_OFFSET + 0x0c)
 #define MT7628_SDM_MAC_ADRH	(MT7628_SDM_OFFSET + 0x10)
 
+#if !defined(CONFIG_NET_MEDIATEK_HNAT) && !defined(CONFIG_NET_MEDIATEK_HNAT_MODULE)
+#if defined(CONFIG_MEDIATEK_NETSYS_V3)
+struct tnl_desc {
+	u32 entry : 15;
+	u32 filled : 3;
+	u32 crsn : 5;
+	u32 resv1 : 3;
+	u32 sport : 4;
+	u32 resv2 : 1;
+	u32 alg : 1;
+	u32 iface : 8;
+	u32 wdmaid : 2;
+	u32 rxid : 2;
+	u32 wcid : 16;
+	u32 bssid : 8;
+	u32 usr_info : 16;
+	u32 tid : 4;
+	u32 is_fixedrate : 1;
+	u32 is_prior : 1;
+	u32 is_sp : 1;
+	u32 hf : 1;
+	u32 amsdu : 1;
+	u32 tops : 6;
+	u32 is_decap : 1;
+	u32 cdrt : 8;
+	u32 resv3 : 4;
+	u32 magic_tag_protect : 16;
+} __packed;
+
+#define TNL_MAGIC_TAG 0x6789
+#define skb_tnl_cdrt(skb) (((struct tnl_desc *)((skb)->head))->cdrt)
+#define skb_tnl_set_cdrt(skb, cdrt) ((skb_tnl_cdrt(skb)) = (cdrt))
+#define skb_tnl_magic_tag(skb) (((struct tnl_desc *)((skb)->head))->magic_tag_protect)
+#define is_tnl_tag_valid(skb) (skb_tnl_magic_tag(skb) == TNL_MAGIC_TAG)
+#endif // NetsysV3
+#endif // hnat
+
 struct mtk_rx_dma {
 	unsigned int rxd1;
 	unsigned int rxd2;
